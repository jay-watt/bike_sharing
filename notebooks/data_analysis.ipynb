{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from data_processing import load_train_and_test_data\n",
    "\n",
    "train_data, test_data = load_train_and_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_count = train_data.shape[0]\n",
    "print(f\"Instances: {instances_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_count = test_data.shape[0]\n",
    "print(f\"Instances: {instances_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Feature and Target Variable Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_types = train_data.dtypes\n",
    "pd.DataFrame(data_types, columns=['Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = train_data.isnull().sum()\n",
    "pd.DataFrame(missing_values, columns=[\"Count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = test_data.isnull().sum()\n",
    "pd.DataFrame(missing_values, columns=[\"Count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicate Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_count = train_data.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_count = test_data.duplicated().sum()\n",
    "print(f\"Duplicate rows: {duplicates_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Datetime Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import transform_datetime\n",
    "\n",
    "train_data_transformed = transform_datetime(train_data)\n",
    "train_data_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = train_data_transformed.nunique()\n",
    "pd.DataFrame(unique_values, columns=[\"Unique Values Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import perform_categorical_conversion\n",
    "\n",
    "train_data_processed = perform_categorical_conversion(train_data_transformed)\n",
    "data_types_after_processing = train_data_processed.dtypes\n",
    "pd.DataFrame(data_types_after_processing, columns=[\"Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis of Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import TARGET_VARIABLES\n",
    "\n",
    "numerical = train_data_processed.select_dtypes(\n",
    "    include=['float64', 'int64', 'int32']).drop(columns=TARGET_VARIABLES).columns\n",
    "\n",
    "def calculate_numerical_statistics(columns, data):\n",
    "    basic_stats = data[columns].describe()\n",
    "    extended_stats = basic_stats.T\n",
    "    \n",
    "    extended_stats['median'] = data[columns].median()\n",
    "    extended_stats['variance'] = data[columns].var()\n",
    "    extended_stats['range'] = data[columns].max() - \\\n",
    "        data[columns].min()\n",
    "    extended_stats['iqr'] = data[columns].quantile(\n",
    "        0.75) - data[columns].quantile(0.25)\n",
    "    extended_stats['skewness'] = data[columns].skew()\n",
    "    extended_stats['kurtosis'] = data[columns].kurtosis()\n",
    "    \n",
    "    return extended_stats\n",
    "\n",
    "\n",
    "calculate_numerical_statistics(numerical, train_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def calculate_subplots_layout(columns):\n",
    "    num_features = len(columns)\n",
    "    num_cols = 2 if num_features < 5 else 3\n",
    "    num_rows = (num_features + num_cols - 1) // num_cols\n",
    "    \n",
    "    return num_rows, num_cols\n",
    "\n",
    "def rotate_xticklabels_if_long(ax, label_length_threshold=5, rotation_angle=45):\n",
    "    labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "    if any(len(label) > label_length_threshold for label in labels):\n",
    "        ax.tick_params(axis='x', labelrotation=rotation_angle)\n",
    "\n",
    "def plot_numerical_distributions(columns, data):\n",
    "    num_rows, num_cols = calculate_subplots_layout(columns)\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(8, 3*num_rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(columns):\n",
    "        sns.histplot(data[feature], ax=axes[i], kde=True, edgecolor=None)\n",
    "        axes[i].set_title(feature)\n",
    "        axes[i].set_xlabel('')\n",
    "        rotate_xticklabels_if_long(axes[i])\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_numerical_distributions(numerical, train_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis of Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = train_data_processed.select_dtypes(\n",
    "    include=['category']).columns\n",
    "\n",
    "train_data_processed[categorical].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_cols = calculate_subplots_layout(categorical)\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(8, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(categorical):\n",
    "    sns.countplot(data=train_data_processed, x=col,\n",
    "                  ax=axes[i], order=train_data_processed[col].value_counts().index)\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xlabel('')\n",
    "    axes[i].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis of Target Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_numerical_statistics(TARGET_VARIABLES, train_data_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import transform_target_variable_data\n",
    "\n",
    "train_data_transformed = transform_target_variable_data(train_data_processed)\n",
    "calculate_numerical_statistics(TARGET_VARIABLES, train_data_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical_distributions(TARGET_VARIABLES, train_data_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis of Numerical - Numerical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train_data_transformed[numerical].corr()\n",
    "corr_df = pd.DataFrame(corr_matrix)\n",
    "\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis of Numerical - Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "results = []\n",
    "\n",
    "for num_feature in numerical:\n",
    "    for cat_feature in categorical:\n",
    "        groups = [train_data_transformed[train_data_transformed[cat_feature] == level][num_feature] for level in train_data_transformed[cat_feature].unique()]\n",
    "        \n",
    "        f_stat, p_value = f_oneway(*groups)\n",
    "        \n",
    "        results.append({\n",
    "            'Numerical Feature': num_feature,\n",
    "            'Categorical Feature': cat_feature,\n",
    "            'F-statistic': f_stat,\n",
    "            'P-value': p_value\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "alpha = 0.05\n",
    "filtered_results_df = results_df[results_df['P-value'] < alpha]\n",
    "ordered_results_df = filtered_results_df.sort_values(by='F-statistic', ascending=False)\n",
    "\n",
    "ordered_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis of Categorical - Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis of Numerical Features - Target Variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
